{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zz2mNhcL6z_O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "2_hKodEY9bEN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  90],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "E0m1KpjA9d6X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "zb3_hQJ79hTW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3cdEQHD9mNv",
        "outputId": "d8149adf-808d-48e4-de93-da77c47ae641"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7f7ce9107a30>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "kG3aFLVs93NQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "r7OxlpMr-TRk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUDED2do-WR1",
        "outputId": "444282ff-2551-4667-9054-4373a2cd754d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 39526.539062\n",
            "Epoch    0/20 Batch 2/3 Cost: 5488.099609\n",
            "Epoch    0/20 Batch 3/3 Cost: 4173.067383\n",
            "Epoch    1/20 Batch 1/3 Cost: 728.667725\n",
            "Epoch    1/20 Batch 2/3 Cost: 257.725159\n",
            "Epoch    1/20 Batch 3/3 Cost: 150.766510\n",
            "Epoch    2/20 Batch 1/3 Cost: 6.438773\n",
            "Epoch    2/20 Batch 2/3 Cost: 26.597240\n",
            "Epoch    2/20 Batch 3/3 Cost: 2.707144\n",
            "Epoch    3/20 Batch 1/3 Cost: 9.134971\n",
            "Epoch    3/20 Batch 2/3 Cost: 4.556644\n",
            "Epoch    3/20 Batch 3/3 Cost: 3.148329\n",
            "Epoch    4/20 Batch 1/3 Cost: 5.681568\n",
            "Epoch    4/20 Batch 2/3 Cost: 7.466197\n",
            "Epoch    4/20 Batch 3/3 Cost: 3.646132\n",
            "Epoch    5/20 Batch 1/3 Cost: 9.360841\n",
            "Epoch    5/20 Batch 2/3 Cost: 1.334047\n",
            "Epoch    5/20 Batch 3/3 Cost: 9.931788\n",
            "Epoch    6/20 Batch 1/3 Cost: 6.067072\n",
            "Epoch    6/20 Batch 2/3 Cost: 11.293395\n",
            "Epoch    6/20 Batch 3/3 Cost: 4.307132\n",
            "Epoch    7/20 Batch 1/3 Cost: 7.703155\n",
            "Epoch    7/20 Batch 2/3 Cost: 3.053269\n",
            "Epoch    7/20 Batch 3/3 Cost: 4.796512\n",
            "Epoch    8/20 Batch 1/3 Cost: 4.579616\n",
            "Epoch    8/20 Batch 2/3 Cost: 7.041720\n",
            "Epoch    8/20 Batch 3/3 Cost: 4.533671\n",
            "Epoch    9/20 Batch 1/3 Cost: 8.779661\n",
            "Epoch    9/20 Batch 2/3 Cost: 3.357415\n",
            "Epoch    9/20 Batch 3/3 Cost: 3.819288\n",
            "Epoch   10/20 Batch 1/3 Cost: 5.470265\n",
            "Epoch   10/20 Batch 2/3 Cost: 7.320075\n",
            "Epoch   10/20 Batch 3/3 Cost: 3.734832\n",
            "Epoch   11/20 Batch 1/3 Cost: 1.031217\n",
            "Epoch   11/20 Batch 2/3 Cost: 6.341755\n",
            "Epoch   11/20 Batch 3/3 Cost: 14.332260\n",
            "Epoch   12/20 Batch 1/3 Cost: 7.913900\n",
            "Epoch   12/20 Batch 2/3 Cost: 10.064148\n",
            "Epoch   12/20 Batch 3/3 Cost: 4.791033\n",
            "Epoch   13/20 Batch 1/3 Cost: 2.360088\n",
            "Epoch   13/20 Batch 2/3 Cost: 12.341305\n",
            "Epoch   13/20 Batch 3/3 Cost: 6.734348\n",
            "Epoch   14/20 Batch 1/3 Cost: 4.152291\n",
            "Epoch   14/20 Batch 2/3 Cost: 3.186766\n",
            "Epoch   14/20 Batch 3/3 Cost: 17.154760\n",
            "Epoch   15/20 Batch 1/3 Cost: 4.831069\n",
            "Epoch   15/20 Batch 2/3 Cost: 8.368036\n",
            "Epoch   15/20 Batch 3/3 Cost: 5.025968\n",
            "Epoch   16/20 Batch 1/3 Cost: 3.152753\n",
            "Epoch   16/20 Batch 2/3 Cost: 6.763087\n",
            "Epoch   16/20 Batch 3/3 Cost: 14.297852\n",
            "Epoch   17/20 Batch 1/3 Cost: 4.753064\n",
            "Epoch   17/20 Batch 2/3 Cost: 4.232740\n",
            "Epoch   17/20 Batch 3/3 Cost: 13.904446\n",
            "Epoch   18/20 Batch 1/3 Cost: 7.669442\n",
            "Epoch   18/20 Batch 2/3 Cost: 5.140097\n",
            "Epoch   18/20 Batch 3/3 Cost: 5.877532\n",
            "Epoch   19/20 Batch 1/3 Cost: 6.276739\n",
            "Epoch   19/20 Batch 2/3 Cost: 4.461980\n",
            "Epoch   19/20 Batch 3/3 Cost: 11.944314\n",
            "Epoch   20/20 Batch 1/3 Cost: 8.003523\n",
            "Epoch   20/20 Batch 2/3 Cost: 9.075539\n",
            "Epoch   20/20 Batch 3/3 Cost: 7.915736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 [73, 80, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[73, 80, 75]])\n",
        "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var)\n",
        "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-vn526C-cli",
        "outputId": "9e6a0101-a295-432e-d8b0-3e8643583ccc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.8369]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **커스텀 데이터셋(Custom Dataset)**"
      ],
      "metadata": {
        "id": "15ibMVGEAejk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 커스텀 데이터셋을 만들 때, 일단 가장 기본적인 뼈대\n",
        "- 여기서 필요한 기본적인 define은 3개입니다.\n"
      ],
      "metadata": {
        "id": "j3bOszjSA7cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "#   def __init__(self):\n",
        "\n",
        "#   def __len__(self):\n",
        "\n",
        "#   def __getitem__(self, idx):"
      ],
      "metadata": {
        "id": "7uF6P5qk_HUo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이를 좀 더 자세히 봅시다.\n",
        "\n",
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "#   def __init__(self):\n",
        "#   데이터셋의 전처리를 해주는 부분\n",
        "\n",
        "#   def __len__(self):\n",
        "#   데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#   데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
        "\n",
        "# len(dataset)을 했을 때 데이터셋의 크기를 리턴할 len\n",
        "# dataset[i]을 했을 때 i번째 샘플을 가져오도록 하는 인덱싱을 위한 get_item"
      ],
      "metadata": {
        "id": "n7L3CfksBP4h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "DndY4fGUDUsS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 상속\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  # 총 데이터의 개수를 리턴\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "poNPW0NyC3n4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "lAPtkGo1DXPK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "BE6GZDcGDbA8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVL8LflRDhG0",
        "outputId": "659825ff-b7a1-41e0-ba39-b05e7387fe37"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 43128.726562\n",
            "Epoch    0/20 Batch 2/3 Cost: 18717.447266\n",
            "Epoch    0/20 Batch 3/3 Cost: 6206.746094\n",
            "Epoch    1/20 Batch 1/3 Cost: 1460.235474\n",
            "Epoch    1/20 Batch 2/3 Cost: 325.045532\n",
            "Epoch    1/20 Batch 3/3 Cost: 79.724876\n",
            "Epoch    2/20 Batch 1/3 Cost: 37.891983\n",
            "Epoch    2/20 Batch 2/3 Cost: 20.062044\n",
            "Epoch    2/20 Batch 3/3 Cost: 12.621596\n",
            "Epoch    3/20 Batch 1/3 Cost: 0.095930\n",
            "Epoch    3/20 Batch 2/3 Cost: 1.770778\n",
            "Epoch    3/20 Batch 3/3 Cost: 5.974853\n",
            "Epoch    4/20 Batch 1/3 Cost: 0.810976\n",
            "Epoch    4/20 Batch 2/3 Cost: 2.525479\n",
            "Epoch    4/20 Batch 3/3 Cost: 5.354998\n",
            "Epoch    5/20 Batch 1/3 Cost: 3.174236\n",
            "Epoch    5/20 Batch 2/3 Cost: 1.418925\n",
            "Epoch    5/20 Batch 3/3 Cost: 2.593330\n",
            "Epoch    6/20 Batch 1/3 Cost: 0.454143\n",
            "Epoch    6/20 Batch 2/3 Cost: 3.403903\n",
            "Epoch    6/20 Batch 3/3 Cost: 1.176445\n",
            "Epoch    7/20 Batch 1/3 Cost: 2.802267\n",
            "Epoch    7/20 Batch 2/3 Cost: 3.741375\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.301648\n",
            "Epoch    8/20 Batch 1/3 Cost: 1.924042\n",
            "Epoch    8/20 Batch 2/3 Cost: 0.186187\n",
            "Epoch    8/20 Batch 3/3 Cost: 5.160681\n",
            "Epoch    9/20 Batch 1/3 Cost: 0.896043\n",
            "Epoch    9/20 Batch 2/3 Cost: 1.711253\n",
            "Epoch    9/20 Batch 3/3 Cost: 5.046239\n",
            "Epoch   10/20 Batch 1/3 Cost: 3.213935\n",
            "Epoch   10/20 Batch 2/3 Cost: 1.719482\n",
            "Epoch   10/20 Batch 3/3 Cost: 0.238433\n",
            "Epoch   11/20 Batch 1/3 Cost: 1.649087\n",
            "Epoch   11/20 Batch 2/3 Cost: 2.824846\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.037612\n",
            "Epoch   12/20 Batch 1/3 Cost: 0.187109\n",
            "Epoch   12/20 Batch 2/3 Cost: 3.416677\n",
            "Epoch   12/20 Batch 3/3 Cost: 1.375724\n",
            "Epoch   13/20 Batch 1/3 Cost: 2.127818\n",
            "Epoch   13/20 Batch 2/3 Cost: 0.309934\n",
            "Epoch   13/20 Batch 3/3 Cost: 4.412718\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.396944\n",
            "Epoch   14/20 Batch 2/3 Cost: 5.563510\n",
            "Epoch   14/20 Batch 3/3 Cost: 0.078152\n",
            "Epoch   15/20 Batch 1/3 Cost: 0.730940\n",
            "Epoch   15/20 Batch 2/3 Cost: 3.394655\n",
            "Epoch   15/20 Batch 3/3 Cost: 0.041018\n",
            "Epoch   16/20 Batch 1/3 Cost: 2.254606\n",
            "Epoch   16/20 Batch 2/3 Cost: 2.055904\n",
            "Epoch   16/20 Batch 3/3 Cost: 0.416799\n",
            "Epoch   17/20 Batch 1/3 Cost: 0.775995\n",
            "Epoch   17/20 Batch 2/3 Cost: 5.021286\n",
            "Epoch   17/20 Batch 3/3 Cost: 0.118563\n",
            "Epoch   18/20 Batch 1/3 Cost: 0.712109\n",
            "Epoch   18/20 Batch 2/3 Cost: 1.463967\n",
            "Epoch   18/20 Batch 3/3 Cost: 5.633669\n",
            "Epoch   19/20 Batch 1/3 Cost: 2.354163\n",
            "Epoch   19/20 Batch 2/3 Cost: 2.306710\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.162606\n",
            "Epoch   20/20 Batch 1/3 Cost: 3.385424\n",
            "Epoch   20/20 Batch 2/3 Cost: 0.491478\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.803192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 [73, 80, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[73, 80, 75]])\n",
        "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var)\n",
        "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAyW3z9JDkiU",
        "outputId": "cd284974-4e79-4cfb-9c1a-67033ee4a86c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[152.0028]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNwdQYUhDqJy",
        "outputId": "626d363d-2b6c-4ca7-91d5-b5c5763adb4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7da1b984b0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "guD3TBKXLlqH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
        ")"
      ],
      "metadata": {
        "id": "ny3UwyOcLo_0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl2INRzmLspA",
        "outputId": "b260bcf6-2bf7-458a-f2d8-3a7a6204f697"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4020],\n",
              "        [0.4147],\n",
              "        [0.6556],\n",
              "        [0.5948],\n",
              "        [0.6788],\n",
              "        [0.8061]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wfl_bUHwMKUR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta-HakLjLx4a",
        "outputId": "aee630b6-ae80-437a-fdf4-6519b506f3ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch   10/1000 Cost: 0.614853 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
            "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
            "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
        ")"
      ],
      "metadata": {
        "id": "7UwT-MWYL3GE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "metadata": {
        "id": "LfmbFsb-NQUN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRcPdinoNRkj",
        "outputId": "82cb8a83-a771-49b9-9ece-8517c96d589b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7da1b984b0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "Y2S06WzANXq0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "metadata": {
        "id": "NE53Q8cZNaXo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BinaryClassifier()"
      ],
      "metadata": {
        "id": "xbhZrLplNeND"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yvostg6NhBg",
        "outputId": "55a1f62b-495f-4d89-8b29-d67b6048b745"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch   10/1000 Cost: 0.614853 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
            "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
            "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWN6v6mcNkH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}